{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5da02c2c-1f78-4936-87dc-2818b20ebd4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-22 11:06:36.203317: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-22 11:06:36.295285: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-22 11:06:36.295354: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-22 11:06:36.295406: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-22 11:06:36.309913: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-22 11:06:36.310939: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-22 11:06:41.159607: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and load the dataset\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "034235a7-ab6d-4cc1-89e4-21bcac645e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "16/16 [==============================] - 29s 632ms/step - loss: 0.6934 - acc: 0.4890 - val_loss: 0.6930 - val_acc: 0.5220\n",
      "Epoch 2/25\n",
      "16/16 [==============================] - 4s 246ms/step - loss: 0.6932 - acc: 0.5025 - val_loss: 0.6931 - val_acc: 0.5220\n",
      "Epoch 3/25\n",
      "16/16 [==============================] - 2s 155ms/step - loss: 0.6933 - acc: 0.4920 - val_loss: 0.6930 - val_acc: 0.5220\n",
      "Epoch 4/25\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.6933 - acc: 0.4895 - val_loss: 0.6930 - val_acc: 0.5220\n",
      "Epoch 5/25\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 0.6932 - acc: 0.4905 - val_loss: 0.6929 - val_acc: 0.5220\n",
      "Epoch 6/25\n",
      "16/16 [==============================] - 4s 226ms/step - loss: 0.6932 - acc: 0.5025 - val_loss: 0.6931 - val_acc: 0.5220\n",
      "Epoch 7/25\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.6932 - acc: 0.4980 - val_loss: 0.6930 - val_acc: 0.5220\n",
      "Epoch 8/25\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 0.6932 - acc: 0.5025 - val_loss: 0.6931 - val_acc: 0.5220\n",
      "Epoch 9/25\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 0.6932 - acc: 0.4920 - val_loss: 0.6930 - val_acc: 0.5220\n",
      "Epoch 10/25\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 0.6932 - acc: 0.4960 - val_loss: 0.6928 - val_acc: 0.5220\n",
      "Epoch 11/25\n",
      "16/16 [==============================] - 6s 397ms/step - loss: 0.6932 - acc: 0.5025 - val_loss: 0.6929 - val_acc: 0.5220\n",
      "Epoch 12/25\n",
      "16/16 [==============================] - 5s 311ms/step - loss: 0.6932 - acc: 0.4950 - val_loss: 0.6927 - val_acc: 0.5220\n",
      "Epoch 13/25\n",
      "16/16 [==============================] - 5s 318ms/step - loss: 0.6932 - acc: 0.5075 - val_loss: 0.6927 - val_acc: 0.5220\n",
      "Epoch 14/25\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.6932 - acc: 0.5025 - val_loss: 0.6929 - val_acc: 0.5220\n",
      "Epoch 15/25\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.6931 - acc: 0.5120 - val_loss: 0.6926 - val_acc: 0.5220\n",
      "Epoch 16/25\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.6929 - acc: 0.5215 - val_loss: 0.6921 - val_acc: 0.5220\n",
      "Epoch 17/25\n",
      "16/16 [==============================] - 2s 139ms/step - loss: 0.6919 - acc: 0.5330 - val_loss: 0.6909 - val_acc: 0.5920\n",
      "Epoch 18/25\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.6893 - acc: 0.5645 - val_loss: 0.6848 - val_acc: 0.6360\n",
      "Epoch 19/25\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 0.6669 - acc: 0.6610 - val_loss: 0.6375 - val_acc: 0.6640\n",
      "Epoch 20/25\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.5750 - acc: 0.7205 - val_loss: 0.5913 - val_acc: 0.6740\n",
      "Epoch 21/25\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.4829 - acc: 0.7820 - val_loss: 0.5769 - val_acc: 0.7340\n",
      "Epoch 22/25\n",
      "16/16 [==============================] - 3s 164ms/step - loss: 0.4280 - acc: 0.8245 - val_loss: 0.5825 - val_acc: 0.7260\n",
      "Epoch 23/25\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 0.3883 - acc: 0.8395 - val_loss: 0.6087 - val_acc: 0.7020\n",
      "Epoch 24/25\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.3473 - acc: 0.8625 - val_loss: 0.6052 - val_acc: 0.7340\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.3300 - acc: 0.8695 - val_loss: 0.6529 - val_acc: 0.7400\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('IMDB Dataset.csv')\n",
    "x = data.iloc[:2500, 0]\n",
    "y = data.iloc[:2500, 1]\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(x)\n",
    "sequences = tokenizer.texts_to_sequences(x)\n",
    "maxlen = 50\n",
    "x = sequence.pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "# One-hot encode the labels\n",
    "binr = OneHotEncoder()\n",
    "y = binr.fit_transform(np.c_[y]).toarray()\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(1000, 16))\n",
    "model.add(Bidirectional(LSTM(16, return_sequences=True)))\n",
    "model.add(LSTM(16, return_sequences=True))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x, y, epochs=25, batch_size=128, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7be1abac-af80-45cb-9327-66094963c05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentiment_analysis_model.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model, tokenizer, and one-hot encoder using Joblib\n",
    "joblib.dump((tokenizer, binr, model), 'sentiment_analysis_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "114d3f85-f309-49d8-b54d-8b79789421ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, binr, model = joblib.load('sentiment_analysis_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "506f360b-7fc5-43a0-96c3-94c41d113702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vatosoa/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sentiment_analysis_preprocessing.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model, tokenizer, and one-hot encoder using Keras functions\n",
    "model.save('sentiment_analysis_model.h5')\n",
    "joblib.dump((tokenizer, binr), 'sentiment_analysis_preprocessing.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1a86f7-3c16-444d-a183-49e0f63f125f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
